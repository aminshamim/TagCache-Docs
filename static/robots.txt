# TagCache robots.txt
# Comprehensive crawling directives for search engines

User-agent: *
Allow: /

# Allow all important pages
Allow: /docs/
Allow: /docs/getting-started/
Allow: /docs/installation/
Allow: /docs/api/
Allow: /docs/examples/
Allow: /docs/performance/
Allow: /docs/configuration/
Allow: /docs/deployment/
Allow: /docs/cli/

# Allow static assets
Allow: /css/
Allow: /js/
Allow: /images/
Allow: /fonts/

# Disallow admin or private areas (if any exist)
Disallow: /admin/
Disallow: /private/
Disallow: /.git/
Disallow: /tmp/
Disallow: /cache/

# Disallow common system files
Disallow: /*.log$
Disallow: /*.bak$
Disallow: /*.tmp$

# Allow search engine bots to access search functionality
Allow: /search/

# Special rules for specific bots
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

# Crawl delay to be respectful (in seconds)
Crawl-delay: 1

# Sitemap location
Sitemap: https://tagcache.io/sitemap.xml
Sitemap: https://tagcache.io/sitemap_index.xml

# Host directive (preferred domain)
Host: https://tagcache.io